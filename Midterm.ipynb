{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fancy-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libs.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the mnist data set.\n",
    "\n",
    "data_mnist = pd.read_csv(\"mnist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sexual-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our test data.\n",
    "\n",
    "col_x = data_mnist[data_mnist.columns[:-1]].to_numpy()\n",
    "col_y = data_mnist[data_mnist.columns[-1]].to_numpy()\n",
    "\n",
    "test_x = col_x[-10000:]\n",
    "test_y = col_y[-10000:]\n",
    "\n",
    "test_5 = (test_y == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "matched-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our model.\n",
    "\n",
    "import joblib\n",
    "\n",
    "model_pipe = joblib.load(\"model_pipe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wired-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and score our model based on y and y_hat.\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def print_eval(y, y_hat):\n",
    "    score_pre = precision_score(y, y_hat)\n",
    "    score_rec = recall_score(y, y_hat)\n",
    "    score_f1 = f1_score(y, y_hat)\n",
    "    return (score_pre, score_rec, score_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "perceived-slovenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9908256880733946, 0.968609865470852, 0.979591836734694)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our model on the test data.\n",
    "\n",
    "y_hat = model_pipe.predict(test_x)\n",
    "print_eval(test_5, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifty-beach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36363636363636365, 0.38095238095238093, 0.37209302325581395)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalue our model on the class's data.\n",
    "\n",
    "data_class = pd.read_csv(\"class_digits.csv\")\n",
    "\n",
    "col_x = data_class[data_class.columns[:-1]].to_numpy()\n",
    "col_y = data_class[data_class.columns[-1]].to_numpy()\n",
    "\n",
    "test_5 = (col_y == 5)\n",
    "\n",
    "y_hat = model_pipe.predict(col_x)\n",
    "print_eval(test_5, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "roman-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.3333333333333333, 0.4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalue our model on the Vess's data.\n",
    "\n",
    "data_vess = pd.read_csv(\"student_11.csv\")\n",
    "\n",
    "col_x = data_vess[data_vess.columns[:-1]].to_numpy()\n",
    "col_y = data_vess[data_vess.columns[-1]].to_numpy()\n",
    "\n",
    "test_5 = (col_y == 5)\n",
    "\n",
    "y_hat = model_pipe.predict(col_x)\n",
    "print_eval(test_5, y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
